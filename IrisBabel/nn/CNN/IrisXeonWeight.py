import torch
from torch import nn

class IrisXeonWeight(nn.Module):
    def __init__(self):
        super(IrisXeonWeight, self).__init__()
        self.conv_128_1x1_1 = nn.Conv3d(128, 64, 1, stride=(1, 1, 1))
        self.norm_c_128_1 = nn.BatchNorm3d(64)
        self.conv_128_1x1_2 = nn.Conv3d(64, 32, 1, stride=(1, 1, 1))
        self.norm_c_128_2 = nn.BatchNorm3d(32)
        self.conv_128_1x1_3 = nn.Conv3d(32, 16, 1, stride=(1, 1, 1))
        self.norm_c_128_3 = nn.BatchNorm3d(16)
        self.conv_128_1x1_4 = nn.Conv3d(16, 8, 1, stride=(1, 1, 1))
        self.norm_c_128_4 = nn.BatchNorm3d(8)
        self.conv_128_1x1 = nn.Conv3d(8, 1, 1, stride=(1, 1, 1))
        self.norm_c_128_5 = nn.BatchNorm3d(1)
        self.relu = nn.ReLU()
        self.relu1 = nn.ReLU()
        self.relu2 = nn.ReLU()
        self.relu3 = nn.ReLU()
        self.softmax = nn.Softmax()
        self.dropout1 = nn.Dropout(0.1)
        self.dropout2 = nn.Dropout(0.1)
        self.dropout3 = nn.Dropout(0.1)
        self.dropout4 = nn.Dropout(0.1)
        self.dropout5 = nn.Dropout(0.1)
        self.dropout6 = nn.Dropout(0.1)
        self.dropout7 = nn.Dropout(0.1)
        self.dropout8 = nn.Dropout(0.1)
        self.dropout9 = nn.Dropout(0.1)
        self.dropout10 = nn.Dropout(0.1)
        self.norm2 = nn.LayerNorm(128)
        self.norm3 = nn.InstanceNorm2d(1)
        self.norm4 = nn.BatchNorm2d(128)
        self.dropout = nn.Dropout(0.1)

    def forward(self, x):
        x1 = self.conv_128_1x1_1(x)
        x1 = self.norm_c_128_1(x1)
        x1 = self.relu(x1)
        x1 = self.dropout6(x1)
        x1 = self.conv_128_1x1_2(x1)
        x1 = self.norm_c_128_2(x1)
        x1 = self.relu(x1)
        x1 = self.dropout7(x1)
        x1 = self.conv_128_1x1_3(x1)
        x1 = self.norm_c_128_3(x1)
        x1 = self.relu(x1)
        x1 = self.dropout8(x1)
        x1 = self.conv_128_1x1_4(x1)
        x1 = self.norm_c_128_4(x1)
        x1 = self.relu(x1)
        x1 = self.dropout9(x1)
        x1 = self.conv_128_1x1(x1)
        x1 = self.norm_c_128_5(x1)
        x1 = self.relu2(x1)
        x1 = self.dropout5(x1)
        x1 = torch.mean(x1, dim = 2)
        x1 = torch.permute(x1, (0, 2, 3, 1))
        x1 = self.norm3(x1)
        x1 = torch.permute(x1, (0, 3, 1, 2))
        x1 = self.relu3(x1)
        return x1