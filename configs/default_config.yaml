# configs/default_config.yaml

# 全局默认配置
data:
  video_path: "data/videos/default_video.mp4"
  level_json_path: "resources/level/default_level.json"
  sequence_length: 16
  channels: 128 # 默认使用ATN特征通道
  height: 64
  width: 64
  num_workers: 0 # DataLoader workers

model:
  generator:
    in_channels: 128 # generator input/output channels should match ATN feature size
    out_channels: 128
    epsilon: 0.03
    num_bottlenecks: 4
    base_channels: 32
  discriminator:
    type: "cnn" # default is cnn
    base_channels: 64
  atn:
    model_path: "path/to/atn_model" # Default ATN model path - MUST BE SPECIFIED
    atn_height: 64 # ATN expected input height
    atn_width: 64 # ATN expected input width
    atn_sequence_length: 16 # ATN expected input sequence length
    atn_num_heads: 4 # ATN attention head count (for mask simulation/vis)

training:
  batch_size: 4
  num_epochs: 100
  lr_g: 0.0002
  lr_d: 0.0002
  b1: 0.5
  b2: 0.999
  seed: 42
  device: "cuda"

  # training/dynamic_gan_balance: GAN 动态平衡策略配置
  dynamic_gan_balance:
    enabled: False          # 是否启用动态平衡策略
    strategy: "loss_ratio_freq_adjust" # 平衡策略：'loss_ratio_freq_adjust' (基于损失比调整频率),
                                        # 'adaptive_lr' (自适应学习率调整), 'none' (不启用)
    freq_adjust_interval: 100 # 每隔多少个训练步数调整一次频率/学习率
    initial_D_freq: 1      # 判别器初始更新频率（每 D_freq 步更新一次 D）
    initial_G_freq: 1      # 生成器初始更新频率
    D_dominant_threshold: 2.0 # 当 D_loss / G_loss_gan > 此阈值时，认为 D 过强
    G_dominant_threshold: 0.5 # 当 D_loss / G_loss_gan < 此阈值时，认为 G 过强
    lr_adjust_factor: 0.9  # 学习率调整的乘数 (例如，0.9表示降低10%)
    min_lr: 1e-6           # 最小学习率
    max_lr: 1e-3           # 最大学习率
    loss_history_window: 50 # 用于计算平均损失的滑动窗口大小

losses:
  gan_type: "bce" # bce or lsgan
  decision_loss_type: "mse" # mse, l1, kl, js (decision map, usually mse/l1)
  attention_loss_type: "mse" # mse, l1, kl, js, topk
  decision_loss_weight: 1.0
  attention_loss_weight: 1.0
  topk_k: 10 # for Top-K attention loss / evaluation criterion

regularization:
  lambda_l_inf: 1.0 # Note: epsilon already enforces L-inf
  lambda_l2: 1.0
  lambda_tv: 0.0
  lambda_l2_penalty: 0.001 # L2 penalty on generator weights, not delta norm

mask:
  use_region_mask: False
  # decision_mask_path: "resources/masks/decision_mask.png"
  # attention_mask_path: "resources/masks/attention_mask.npy"

logging:
  log_dir: "runs/default_train"
  checkpoint_dir: "checkpoints/default_train"
  log_interval: 10
  vis_interval: 50
  save_interval: 10

evaluation:
  eval_interval: 5
  success_threshold: 0.1
  success_criterion: "mse_diff_threshold" # mse_diff_threshold, mean_change_threshold, topk_value_drop, topk_position_change
  # topk_k for evaluation success criterion comes from losses.topk_k

# Visualization parameters (can be separate or part of logging/evaluation)
visualization:
  num_vis_samples: 4
  sequence_step_to_vis: 0 # 0-indexed
  num_vis_heads: 1 # for attention visualization
